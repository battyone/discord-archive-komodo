AuthorID;Author;Date;Content;Attachments;Reactions;
"455741312273219595";"jl777c#5810";"04-Aug-19 08:30 AM";"let me try that, it will be easy enough";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 08:44 AM";"it detected and stopped on on block 18, second block with DAA active";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 08:51 AM";"have to clear the precedence flag so the e^x can kick in even if min() was triggered, but only if the 100x booster was triggered";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 09:04 AM";"now it should be like the blood pressure measuring process, where hashrate is the ""blood pressure"" and the 100x is the very tight armband, the e^x will reduce this until it is solved. not sure why the e^x converges so fast to actual hashrate, but since it does, might as well take advantage of it.
with the first 17 blocks mined at diff of 1, immediately on block 18 it is stuck with a 100x harder diff.
after 7 minutes the e^x starts and when it solves, it is a decent estimate of actual hashrate, so instead of free blocks here, it is immediately taking longer very immediately. i guess for a more normal test, i need to ramp up to 15 after it has stabilized with 1 core in the previous 17 blocks, but i want to see the blood pressure result";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 09:05 AM";"strangely it found block 18, and diff only went to 1.38, its the strange relation between bnTarget and diff, especially when starting at easy diff. but 19 is also triggered the 100x boost. curiously it took just about a minute to solve 18, just coincidence it seems";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 09:21 AM";"fixing some control flow, trying again";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 09:25 AM";"and again";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 09:26 AM";"it worked as it should have, but error in doing the e^x calc. this next one could be the one";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 10:38 AM";"I think the jumps are going to work really well.  I'm reducing the code as much as possible. It's going to use prevTarget a alot, no SMAs.  It should reach 1000x in 5 blocks if the attacker is 1 E6, and 500k in 2 more blocks.  It should catch smallish attackers.  When the triggers stop, digishield will have 17 good targets and solvetimes to take over from there.  There can't be any excess blocks emitted.  The only attack  without having to pay a much higher difficulty is to get 3 blocks faster than others once every 6 block.";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 10:39 AM";"smaller attackers will take longer to detect.";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 10:40 AM";"It seems like using the current solvetime to adjust difficulty prevents the need to match rises and falls mathematically.  They can do their job independently.";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 10:42 AM";"I mean my concerns for symmetry may go away if  the rises and falls inherently and independently prevent too many or too few  blocks from being emitted.";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 10:45 AM";"sounds great!";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 12:50 PM";"Is chain work calculated in the database, not in the header?  If chain work is only in the database  and calculated from past  nBits, I think it will be safer to not mess around with adjusting it.";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 12:52 PM";"On the other hand, not having the actual chain work available is risky.";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:44 PM";"it is in RAM, derived from the nBits";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:45 PM";"as long as the nBits represents the actual work, it should be fine. now we are making sometimes different work than should be, but then it goes onchain, so i think it is close enough";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:52 PM";"so the e^x seems ok as the actual work performed goes into the nBits";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 01:52 PM";"To decide longest chain, it's good to be precise about the chain work to avoid manipulation";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:52 PM";"yes, the more the effective work deviates from onchain work, the more chances for manipulation";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:53 PM";"in any case the e^x works so much faster by putting the solved diff onchain";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:54 PM";"given two forks of equal length, the one with more work should win, which means the e^x that is solved with an earlier timestamp";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 01:55 PM";"I guess what they solve is what they solve and that is the actual work, so I should not worry about the actually avg difficulty they saw";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 01:56 PM";"I'm slowly getting there.  It really confusing trying to make sure my loops are correct.";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:56 PM";"probably in some sort of edge cases it would matter what they were trying to solve vs, what actually got solved, but with the actual solving going onchain, it should protect us from most all manipulations";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 01:56 PM";"if you can describe your algo clearly, i can deal with all the loops but it sounds like you are trying to get the simulator working";"";"";
"352488299077566475";"zawy#5864";"04-Aug-19 02:46 PM";"I can't describe it because it's a concept I'm trying to program into existence with pseudocode.";"";"ðŸ˜„ (1)";
"352488299077566475";"zawy#5864";"04-Aug-19 04:27 PM";"Crikey, nearly 24 hours to deduce 3 lines of code.";"";"";
"455741312273219595";"jl777c#5810";"04-Aug-19 04:30 PM";"i tried dozens of boost variations and while it improves things a bit, it feels a deadend that wont reach the full goals, so however long it takes, it is worth it. also the more functionality in the fewest lines is always difficult.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 11:52 AM";"@jl777c On numerator and denominator, why do you use int32_t instead of int?";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 11:54 AM";"it is best to know 100% of the time the size of all variables";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 11:54 AM";"if different instances use different int sizes and there is an over/underflow, then we get a consensus problem";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 11:55 AM";"by always using intXX_t, then no matter what OS, compiler, CPU, the size is the same, so as long as there are no critical bugs in the OS, compiler, CPU, the code will be in consensus";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 11:55 AM";"defensive technique";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 11:56 AM";"for test code it isnt needed, this level of paranoia";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:01 PM";"All systems should view int as int and if it's a constant so that under/over is known to be impossible.  Using int on any signed  integer type like int64_t should always be OK. The only problem I can remember is if you do a conditional on signed verses unsigned.  For example, I wuold not have thought this was necessary, but only because it's not a conditional   
```bnSum *= arith_uint256(int32_t numerator);``` I'm wanting to write the code where you will not want to do any type changes within the algorithm so it remains more clear.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:02 PM";"but I was reluctant to make everything  arith_uint256";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:03 PM";"but doing it that way would not hurt anything";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:04 PM";"There are some big C++ gurus that say always use the same type everywhere if at all possible.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:08 PM";"I'll use arith_uint256 everywhere";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:11 PM";"you can mix the sizes, just specify what it is. i know for a fact some windows compilers default int to be 32 bit even on 64-bit CPU";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:11 PM";"so depending on how your compiler is setup, it will work or no";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:11 PM";"that is a chance i dont want to take";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:12 PM";"recently we were bitten by this exact issue on windows with an unexpected 32 bit size in windows";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:12 PM";"OK, I'll make literally everything arith_uint256";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:13 PM";"that is overkill though, people might think it is needed to be so big. maybe int64_t is a good default to use, with arith_uint256 for only when it is needed. but whatever is comfortable for you is fine";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:18 PM";"```
arith_uint256 zawy_targetMA(...int32_t numerator... )
{
    bnSum *= arith_uint256(numerator);
}
```";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:20 PM";"yes, that is perfect!";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:20 PM";"defines the range of numerator, converts only as needed. clear and efficient";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:21 PM";"lol, I'm complaining about that which is what you did....seeing that makes me want to make everything arith_uint256";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:22 PM";"should minimize the number of conversions";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:22 PM";"probably not that much of overhead, but still moving about 32 bytes vs 4, is 8x the memory movement";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:23 PM";"but these are implementation things";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:23 PM";"it had to convert  because you didn't go ahead and declare it like that";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:24 PM";"Yes, but see, I can't read other people's programming.  I do not read other people's progamming.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:24 PM";"I can't figure it out. I can write a compression routine faster than I can read the same algo in someone elses code";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:25 PM";"defining the algo shouldnt get too involved in all these details, let the coders deal with types, conversions and overflows";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:25 PM";"i guess, just go ahead and make everything arith_uint256 is a good solution for you";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:25 PM";"no need to worry about any type issues";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:26 PM";"Right, but I do not even know what your boost is doing because it takes me a lot of work to read code.  So if you have any trouble with my code or want to change it and then show me how your changes affected the results, I'm clueless about the discussion";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:29 PM";"best to just ask me about any details that are not making sense";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:31 PM";"i disabled all the boost stuff as it slowed down the diff adjustment, and the net gain wasnt enough";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:48 PM";"I can't form much of an opnion on anything because I don't know exactly what you've got.  I want to get code correct and ask for minimal changes so that I can participate better.  I will need to see sovletimes (or timestamps) and difficulty (or targets) in CSV.  Try not to change variable names.  I have not complied what I'll give you.";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:56 PM";"ok";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 12:57 PM";"I like using only 1 or 2-character variables because  math is restricted to 1 character per obect. Math does this so that names do not cloud the logic.";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 12:59 PM";"ok, i will keep it as similar as possible, just to make sure it compiles";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 02:04 PM";"I have N=3, 6, 12 windows to replace the SMAs.  Do testing with only N=3 at first because it's most likely to have oscillation and emission rate problems.";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:06 PM";"ok";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 02:47 PM";"OK, here it is.  I hope it works.  https://github.com/zawy12/difficulty-algorithms/blob/master/difficulty_jump.cpp";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:57 PM";"ok, i think i can understand most of what the code needs to do, just a few things:
```    for ( int j=past-1; j<= 1; j--) {```";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:58 PM";"i think that should be j>=W, as you are using ts[j]-ts[j-W], so j needs to be at least as big as W";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:58 PM";"i assume ts[0] is the most recent solve time, ts[1] the second? or does it start with the nTime in the current block";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:59 PM";"also ```            for ( int i = j; i <= 0; i-- ) {```";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 02:59 PM";"seems i>=W instead of i<=0. maybe the j should start with past+W-1 ?";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:05 PM";"Yes to all questions. I had changed the sign at some point. Also the TS are timestamps not solve time.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:08 PM";"Notice that there are no constants in the algorithm except for what the poisson distribution required which is the numerator and denominator for the given window size. This means I was not able to inject an opinion or tweak it. So it is something like a deep fundamental solution if it works.";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:24 PM";"I think a 1000x attack is supposed to see 600x difficulty on 4th block";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:24 PM";"ok, i hope you dont mind, but i will need to change to C for efficiency and change a few data types, but i will keep the variable names the same. i see nTime is used as the currently mined blocks time, so all answers i have. now just need to fit it into ZAWY16";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:24 PM";"i will just use W=3 for now instead of the symmetric SMA?";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:25 PM";"but later we can combine multiple W values via min()/max()";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:26 PM";"yes, and no average.  It is like the SMAs with the tipdiff I already showed you, but it's refined to trigger more easily and jump a lot more,  and  to stop excess block release";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:27 PM";"very cool! I will just pop it in there in the control flow as that is already working framework.  so the exponential decay is still needed";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:27 PM";"With multiple W's, select min bnTarget that they reutn";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:28 PM";"this is just for the min() case then? and we rely on exponential for the max() side?";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:28 PM";"this has the potential of jumping way too high, so exp definitely";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:28 PM";"the exponential is the safety net";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:28 PM";"allows to be super aggressive. i like it";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:29 PM";"also your assumption that blockchain cant store state is maybe something we can change, if storing state would make things better";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:29 PM";"how much state info is needed?";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:29 PM";"yes, it would prevent need for the loops.";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:30 PM";"already there are things like nHeight that is not onchain, but in the in-memory CBlockIndex data";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:30 PM";"loops of 50 is no big deal though";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:31 PM";"oh, i see a ts[-1], by that you mean nTime of mined block?";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:31 PM";"We need to know block number of of most recent, most aggressive trigger., and then loop through 3 or more Ws to determine which one";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:32 PM";"oh, if I have a ts[-1] it needs correcting...probably suppoed to be 1";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:32 PM";"ts[-W] also...";"";"";
"455741312273219595";"jl777c#5810";"05-Aug-19 03:32 PM";"line 64";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:33 PM";"```if ( ts[j]-ts[j-W] < T*numerator/denominator ) {```";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:33 PM";"change to ```if ( ts[j]-ts[j+W] < T*numerator/denominator ) {```";"";"";
"352488299077566475";"zawy#5864";"05-Aug-19 03:33 PM";"+W";"";"";
