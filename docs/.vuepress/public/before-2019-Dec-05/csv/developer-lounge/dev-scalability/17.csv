AuthorID;Author;Date;Content;Attachments;Reactions;
"455021680935436290";"Gateway#3763";"19-Jun-18 02:42 PM";"[slack] <tolken> Is there any upcoming big scaling test scheduled, or devs back to the drawing board, tuning?";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 02:45 PM";"Yeah, we are actually very close.";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 02:48 PM";"I have a call with AWS tomorrow morning regarding funding and securing enough infrastructure. I have a working set of containers that use 1 vCPU per chain, to fill blocks with 1 payment and 100 payment Transactions. 
The last thing needed is the DynamoDB to aggregate data.  Mylo(KomodoPioneers) started on this, and its a great solution, but he hasnt got the time right now to work on it. 
I started on this today, and think I have got a solution that will work just fine but I need to check with AWS tomorrow I am understanding how the DynamoDB works.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:07 PM";"[slack] <tolken> Heya blackjok3r, fantastic work on all of this, I hope you‚Äôre well compensated for all the heavy lifting you‚Äôre doing these days :)";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:09 PM";"[matrix] <blackjok3r:matrix.org> I have had plenty of help. I am learning a LOT too which is good fun.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:09 PM";"[slack] <tolken> Not just you of course, but just in awe watching you guys fire this mutha up.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:11 PM";"[slack] <tolken> Maybe later this year I‚Äôll be able to help in some capacity. Just need to fix pesky job problem (the fact that I have one)";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 03:11 PM";"I cannot wait either. This time will be much better than last.  I really hope we can do 1 million single payments. I cannot see why we cant from my tests so far as everything is distributed this time, much better than last attempt.";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 03:12 PM";"Yeah I have no job, so can spend most of my time on this. Not sure how much longer for though, need to get this finished off soon.";"";"";
"456490768589258753";"ComputerGenie#2331";"19-Jun-18 03:13 PM";"what is this ""job"" thing you guys speak of? ü§î";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:13 PM";"[slack] <tolken> I‚Äôm going to send you a little kmd to help. I‚Äôll hit you up for your kmd address in a couple days.";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 03:14 PM";"yeah, I been away from ""job"" since last august. Learn't a LOT since coming here. Your OK man, I do have share in a-team NN, which pays quite well. Although I wont say no lol.";"";"";
"456490768589258753";"ComputerGenie#2331";"19-Jun-18 03:15 PM";"_can't imagine ever working some someone else again_";"";"üíØ (1),üëå (1)";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 03:16 PM";"hopefully I dont have to. I really dont want to lol.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 03:16 PM";"[slack] <tolken> You an always share it with the a-team too. Not much but just to show my appreciation.";"";"";
"232679450301431808";"blackjok3r#3181";"19-Jun-18 03:17 PM";"appreciated dude. üòÑ";"";"";
"433325854228217857";"WaseemQ#6781";"19-Jun-18 03:36 PM";"Kmd life";"";"";
"412323938782150658";"SHossain#0007";"19-Jun-18 04:34 PM";"Pinned a message.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 04:43 PM";"[slack] <Steve Lee> @ @ our first request for aws funding has been approved. Which one of you needs the codes for redemption?";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 04:44 PM";"[matrix] <n2okpride:matrix.org> blackjok3r: patchkez our first request for AWS funding was approved. Who needs the promo codes for redeption?";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 05:01 PM";"[matrix] <patchkez:matrix.org> n2okpride: good news! as we will use 1 AWS account we can apply the codes as we need them. For now I personally need to test deployment of few few chains to Kubernetes cluster and mylo5ha5 needs to finish DynamoDB configuration but I think he uses his AWS account for testing.";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 05:03 PM";"[matrix] <n2okpride:matrix.org> can you dm me your email address?";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 05:12 PM";"[matrix] <patchkez:matrix.org> done";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 05:47 PM";"[matrix] <patchkez:matrix.org> [blackjok3r](https://matrix.to/#/@blackjok3r:matrix.org): please ask AWS tomorrow what are the limits for their Kubernetes cluster. 
1. What is the maximum number of containers and pods which can be deployed to cluster
2. How many containers/pods per instance is allowed";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 05:48 PM";"[matrix] <patchkez:matrix.org> 3. Or any other limitations, I did not find anything related to limits in their documentation";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 06:15 PM";"[matrix] <patchkez:matrix.org> applied first promo code into Komodoplatform AWS account:";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 06:16 PM";"[matrix] <patchkez:matrix.org>";"https://cdn.discordapp.com/attachments/449949868904022036/458696545483751424/screenshot-20180619201356.png";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 06:19 PM";"[matrix] <patchkez:matrix.org> blackjok3r: mylo5ha5 we can start preparing AWS infra for the real test. I am going to test creation of K8n cluster + persistent volumes for assetchains";"";"";
"455021680935436290";"Gateway#3763";"19-Jun-18 06:21 PM";"[matrix] <patchkez:matrix.org> mylo5ha5: do we still need to perform test how much requests DynamoDB can handle?";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"19-Jun-18 11:10 PM";"@SHossain the tx_stream repo is outdated, it uses the insight apis which is no longer how we get the info. We now use blocknotify. 
I've left tx_stream as is because it might be useful for other things involving insight apis which many coins offer. 
I'll push the updated script once DynamoDB is feeding out data (set to random at the moment).

https://github.com/smk762/txscl_vis is up to date, front end for the metrics.";"";"";
"412323938782150658";"SHossain#0007";"19-Jun-18 11:11 PM";"https://github.com/patchkez/scaletest_containers
https://github.com/blackjok3rtt/ScaleTestV2
https://github.com/smk762/txscl_vis
https://github.com/Meshbits/TxBlaster
https://github.com/dwygit/komodotools/tree/master/dwy/speedtest
http://pad.supernet.org/Stress_Test_Signups";"";"";
"412323938782150658";"SHossain#0007";"19-Jun-18 11:11 PM";"Pinned a message.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"19-Jun-18 11:12 PM";"ü§ò";"";"";
"455021680935436290";"Gateway#3763";"20-Jun-18 12:24 AM";"[matrix] <ross.t:matrix.org> https://petertodd.org/2015/why-scaling-bitcoin-with-sharding-is-very-hard";"";"";
"455021680935436290";"Gateway#3763";"20-Jun-18 12:25 AM";"[matrix] <ross.t:matrix.org> Just something I ran into- read it or not";"";"";
"456226577798135808";"Deleted User#0000";"20-Jun-18 01:43 AM";"Good luck boys! To 1 million and beyond üöÄ";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 03:00 AM";"We just need 8196 vCPU's lol";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 06:03 AM";"alright i've got 72 hours  til my next fiat commitment and 1 or 2 social engagements.  working on AWS stuff and some internal kmd stuff.  should be a good few days üòõ";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:16 AM";"I just goe the DynamoDB working";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:16 AM";"I changed your feilds from id";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:16 AM";"to chain, and sorted them by timestamp";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:16 AM";"litterally just finished";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:16 AM";"all we need to do with this now, is create a trigger than feeds smk702";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:17 AM";"I will push code to my git. I forked your repo";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:18 AM";"https://github.com/blackjok3rtt/scaletest-blocknotify/tree/master";"";"ü•Å (1)";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:19 AM";"Not 100% on how you fetch it, but it sorts the chain by timestamp so it should be only a matter of fetching the last 1000 entries with a trigger and lambda API";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:19 AM";"@Mylo";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:20 AM";"just need to put in a few more entries to my table to verify it works correctly though. I have only pushed a single chain, and manually changed the timestamp to verify it sorts properly";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:21 AM";"ü§î";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:22 AM";"It sorts by chain name... darn it... cant make timestamp main key, because that would need a single shard of hte DB would gett hammered every second there is multiple blocks. üò¶";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:32 AM";"Ok... If I can figure out how to issue a scan call, you can sort and retrieve anything greater than or equal to a timestamp.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:32 AM";"I can get it to work on AWS console... Just dunno how to issue that call in node.js..";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:18 AM";"nice work getting rid of `id`.  yeah the `hash` just needs to be `chain name` and the `range key` is the timestamp or block üòÑ";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:19 AM";"Yeah its just fetching it... I think using scan, will be very costly";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:19 AM";"as it will eat up a lot of write units fetching the entire table every3s";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:19 AM";"is `query` cheaper?";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:20 AM";"There is a way to use a fetch trigger";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:20 AM";"query simply does not work, you need to query each chain seperatly";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:20 AM";"thats even worse than pushing all the data directly to SMK's DB";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:20 AM";"ok cool.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:21 AM";"chain name was the only key we have that fits the description of what the main krey value needs to be. Otherwie the DB is designed badly and will throttle and break";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:21 AM";"If I can figure out these stupid role things, I can make a trigger/stream where he can just fetch the last 1000 entries";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:21 AM";"and filter out what every he already has";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:22 AM";"then we only have to pay for writes üòÑ";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:23 AM";"yeah dynamodb (nosql) design is different to relational.  chain name as hash/key is cool.";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:23 AM";"scanning a whole table shouldn't be too costly.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:23 AM";"it took me most of the last 16h to get my head around it... I spent hours last night watchin youtube lol";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:23 AM";"Yeah I guess we just try it, and see what it costs for 64 chains";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:23 AM";"it's only going to have 500 blocks to fetch for the scale test.";"";"üëç (1)";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:24 AM";"it should be linear... as each chain is a ""shard""";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:24 AM";"yeah";"";"";
"371114647052615681";"Mylo#8306";"20-Jun-18 07:24 AM";"one scan that fetches 100 blocknotify data things takes 0.2s or so.";"";"";
"455021680935436290";"Gateway#3763";"20-Jun-18 07:25 AM";"[matrix] <ross.t:matrix.org> https://bitcoinmagazine.com/articles/op-ed-many-faces-sharding-blockchain-scalability/";"";"";
"455021680935436290";"Gateway#3763";"20-Jun-18 07:25 AM";"[matrix] <ross.t:matrix.org> Last post - I can see it but cannot touch it - make it real - have a good week guys - kill it";"";"";
"455021680935436290";"Gateway#3763";"20-Jun-18 07:25 AM";"[matrix] <mylo5ha5:matrix.org> Don‚Äôt need but nice to know how much to provision for cost management (if there were no credits available)";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:26 AM";"yeah the thing should be able to scan the whole DB in no time... even a 1minute lag is nothing really.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:26 AM";"From my research some users of it have 40TB tables...";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:26 AM";"Crazy";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:26 AM";"we will be lucky to reach 20mb for entire test.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:27 AM";"mySQL would have handled the laod, but getting the data to it is a mission.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:27 AM";"ok I will go the scan route for now, as thats much easier to implement";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 07:28 AM";"if thats no good we can look at a data stream.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 08:42 AM";"we can change 3 sec to 5 sec to reduce number of queries";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 08:43 AM";"just need to find the optimum balance between write units and payload size";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 08:45 AM";"136.5 records per sec is the average for 8192 chains. say 500 for 3 sec and 1000 for 5 sec with a bit of wiggle room.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 08:47 AM";"if timestamp defines records returned, num of records will vary, so shouldnt lose any blocks. just need to handle  anticipated edge cases in payload size.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 09:12 AM";"I am not sure how many read ""credits"" are used on a scan. We will have to test it on 64 chains over say 10 minutes and then see. tbh I dont think we are going to hit any crazy numbers, this DB is designed to handle TB's of data, and we are dealing with bytes lol.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 09:45 AM";"at a glance, if json records (following format in mylos csv)  for each scan have to be less than 1mb, we can handle at least 5000.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 09:46 AM";"odds of 5/8ths of the chains reporting completed blocks over the 3 second  window is slim.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 09:50 AM";"if read credits become the limiting factor, we can stretch time interval. it'll increase chances of excessive block completion during interval, but error rate should still be marginal.";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 10:33 AM";"It would be good if I could getr a result from trying to do a scan that did not result in ""Interal Server Error 500"" üò¶";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 10:42 AM";"any info in cli logs?";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 10:47 AM";"even if i could print things to the console logs... thats how I do all of my bash scripts...";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 10:47 AM";"trial and error";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 10:47 AM";"üòÇ";"";"";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 04:30 PM";"ok. we have stats data most of the way there üòÑ 
Thanks to @smk762 -  dracocanis ominator  For his excellent work once again. Pulling the data straight from the DynamoDB into the stats website back end..";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 04:36 PM";"data get done. yet to procecess into the rest of the vis, but it's past midnight so job for later today. when the sun is up.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"20-Jun-18 04:36 PM";"js for db scan  at https://github.com/smk762/txscl_vis/blob/master/js/scan_db.js";"";"üíØ (1),ü•â (1),üëå (1)";
"232679450301431808";"blackjok3r#3181";"20-Jun-18 06:19 PM";"Ok been awake for 20H. Found a few bugs in TxBlaster due to sync issues. I think they are fixed. Will run another test tomorrow or the next day once the stats site is hooked up.";"";"üò´ (1),üëç (1)";
"459028995024093194";"kmdkrazy#8280";"20-Jun-18 07:39 PM";"Only 4 more hours to fill the day @blackjok3r";"";"";
