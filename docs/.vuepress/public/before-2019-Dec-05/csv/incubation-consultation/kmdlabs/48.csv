AuthorID;Author;Date;Content;Attachments;Reactions;
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 09:23 AM";"like git rm assetcahins.json \ git add . \ git commit -m ""sort your shit out git"" \ git push \ oraclefetch.sh \ make_acjson.sh \ git add . \ etc. \ etc. \";"";"üëç (1)";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 09:24 AM";"its a bit clunky, but I dont have a scalpel right now";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:37 AM";"nar we can git ignore assetchains.json and then host the web  accessable file somwhere else";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:37 AM";"I think I might do that tonight... I cna just put it here http://103.6.12.112:8080";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:38 AM";"just have a cron, that pulls oracle from B1 then passes it through jq to check that its valid and copy to webserver folder";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:38 AM";"its not great, but for now it will work, and that server has had 0 daown time, so far since I put it in, apart from a few times I needed to restart host because I broke it.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:39 AM";"an AWS lambda endpoint might be the best thig to use to make sure its always up, and they are free... at least until we figure somethign better out.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:40 AM";"ideally explorer API can just return it , but it would need a lot of work.";"";"üëç (1)";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 09:52 AM";"if we add 
`echo $HOME/StakedNotary/assetchains.json` 
to the end of `https://github.com/StakedChain/StakedNotary/blob/master/oraclefetch.sh`
could we `cat $(./oracleftech.sh)` ?";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 09:53 AM";"Still not sure thats the best folder to hold it though, unless thats what non notaries are going to clone";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 09:54 AM";"might be better housed in ~/.komodo/STAKED";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 09:59 AM";"for the notary nodes you solution seems quite good ... but for other things  ...B1 might not be running";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:00 AM";"like the reop it made just staked .. which just fetches the json, and builds the correct branch to start a single chain.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:07 AM";"d'oh. well heres this anyways... https://github.com/StakedChain/StakedNotary/pull/15";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:09 AM";"I figured the oraclefetch script if $orclid and $sub end up $1  $2, it's a handy trick. I""ll probably use it for the gps thing. Still not 100% batons are what I think they are though. about 98%... and rising.";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:10 AM";"any use in that particular oracle running on all chains?";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:10 AM";"rising tx fees?";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:11 AM";"It can on all chains no problem I think.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:11 AM";"That was also another option I was thinking of... but it can get harder to manage";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:12 AM";"In my testin I did something simliar to with dice, where it populates all chains with an oracle";"";"üëå (1)";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:12 AM";"I wont merge that in yet, will speak to alright and see what he rekons, but for notary nodes it seems a good solution";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:13 AM";"the echo cant hurt being in there. using dirrefernt path might upset some other code though";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:14 AM";"Yeah I need to have a good look at it. and test myself... now you guys are ipdated I can use my node to test without breaking he MoMoM tests running on the new chains.";"";"";
"412482228359266328";"CrisF#3405";"23-Oct-18 10:15 AM";"I'm updated.  S1  & PERC no notorization since (1 .5 hours)
W1 no notarizations for 1day 10 hours.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"W1 seemed to be stalled.... I couldnt test on it ... likely has no miner";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"I am using B1 and the 3 new chains";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"S1 and TROLL both died";"";"";
"412482228359266328";"CrisF#3405";"23-Oct-18 10:16 AM";"I'll start cpu mining W1";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"so we removed them";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"I killed that troll chain real good testing streamer";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:16 AM";"the chain isnt even valid any more";"";"";
"412482228359266328";"CrisF#3405";"23-Oct-18 10:16 AM";"I saw that. RIP";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:18 AM";"I'm done trying to modify my pool scripts. they can die too, I'll grow something new from the ashes.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:25 AM";"haha yeah sorry about that .. I really didnt want to move to seperate binaries for diffrent chains either, but after some thaught the power it opened up for the the project made it worth it ...";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:25 AM";"Chains can have contracts enabled, without forcing all chains to acativate  them.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:26 AM";"Thats actually very important";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:33 AM";"would it be weird to put my scripts into oracles, then they access the  assetchains.json oracle, and manage the gps oracle then do something about another oracle being a meta-oracle?";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:34 AM";"No ... oracles are super powerful, do the coolest thing you can possible imagine üòÑ";"";"";
"448777271701143562";"smk762 -  dracocanis ominator#7640";"23-Oct-18 10:43 AM";"if I understand right, batons are the txidchains of the oracle, reaching back and marching forward. now if we have oracles creating oracles and communicating with existing oracles, there is virulent potential of fractalised oracle matrix with a mycological network structure and (along with stream's data xfer rate) near total recall, which will ineviatbly grant us the  to the ability to accurately navigate through the 5th dimension using fungal GPS. Then we can a go back, deafeat skynet before they wipe us out and make sure Biff doesn't become president.";"";"1M (2)";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:58 AM";"HAHA";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:58 AM";"Stream isnt using oracles btw ... I used a much simpler method, to make sure it had the minimum data overhead.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 10:59 AM";"getting the data though was one thing, but assembling it back together is another, didnt get to spend much time on it today, but did get these new chains up an another very long momom test started.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 11:01 AM";"I think if we get a 100% suces rate with 2 chains and 15 freq we can start adding more chains and see if there is a limit.";"";"üëç (1)";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 11:02 AM";"If its slower to migrate it is ... but as long as it always works ...";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 11:02 AM";"I for one dont mind.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 11:02 AM";"its not like people would be using it that often.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:46 PM";"thinking about this streamer and how to get the data out of the chain as fast as possible";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:47 PM";"I am thinking to use the code where it looks for notarisations, to store the txid of every transaction with an OP_RETURN beginnig with 72 0's as an indeex of where each  stream begins.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:47 PM";"then an RPC that can fetch this index";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:47 PM";"and an RPC that takes a txid and a size of data to return";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:49 PM";"this kind of makes redundant the previous txid sent in each tx ... but if someone wanted to jump in half way through they can just call another RPC that fetches any tx happening at the current block height and returns X data back";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:49 PM";"by iterating back through the txs";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:49 PM";"ü§î";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:49 PM";"maybe Im over complicating it though ...";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 12:50 PM";"my first thaught was to just spit the data to a file from connect block... but that only allows to extract the data on chain sync";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:49 PM";"üòÇ";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:49 PM";"definatly over thinking it";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:49 PM";"Pulled out 100MB of data with bash and JQ in 1 min and 30 seconds";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:51 PM";"I dont even think the previous txid needs to be there, just a seq number would work just fine, as all I did to get the data out is :
get block 
list tx
iterate from TX 1 to second last TX
get next block

as each TX feeds the vout to vin of the next TX they are in order in every block. Not a single seqid out of place.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:52 PM";"I think an RPC that tells you what TX the stream starts in would be useful and quite easy to do. Apart from that not much extra is required.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 02:52 PM";"good old -blocknotify will get the data out just fine, under live stream conditions.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 04:46 PM";"managed to hack together an RPC that can pull all of the Op_RETURN scriptpubkeys sent from marektmaker in hex from each block... so -blocknotify  to the app will just stream all data pushed via JSON array in chuncks ... might be easy enough to join all chunks in a block then return the seqids start -> finish and data as option.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 04:47 PM";"this along with changin the previous txid in each chunk to just the first txid sent should enable very fast send and fetch.";"";"parrot (2)";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 04:48 PM";"receive any TX then use the TXID included to fetch that TX, extract block height that tx was in, then pull new RPC from each block, seek is enabled by seqid RPC that returns no data.";"";"";
"232679450301431808";"blackjok3r#3181";"23-Oct-18 04:48 PM";"Ths is turning out really well üòÑ";"";"";
"371114647052615681";"Mylo#8306";"23-Oct-18 11:21 PM";"sounds good.  see how it goes.   assuming good network conditions should work.   we can work out problems later like dropped packets or because you can't control the path of the packets and they arrive out of order use whatever the original thoughts on seq id were i guess.";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 12:18 AM";"@Mylo that cannot happen";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 12:19 AM";"Since when do blocks inna chain build out of order?";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 12:19 AM";"There is literally no chance that the data can get out of order or packets can drop";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 12:21 AM";"Once 1 blocks arrives you can use the data on that block to find the first block that the stream started in then fetch the data from that block and pull each block in sequence, if you don't want all the data you pull each.block in sequence with false flag so all it tells u is what data the block has but does not return the actual data";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 12:25 AM";"I am using confirmed blocks nor mempool, mempool is unreliable and when you can make blocks every 5s it seems no reason to use mempool.";"";"";
"371114647052615681";"Mylo#8306";"24-Oct-18 12:36 AM";"oh ok cool, confirmed blocks makes sense.
have to test on flakey connection, path of packets might not follow the same way and some tx won't be in order/block expected - that's my guess, with bad network.   but that is something to test after it's working.  that's my hunch üòÉ";"";"";
"371114647052615681";"Mylo#8306";"24-Oct-18 12:37 AM";"tx might not arrive to fill in block.   so if it's 10ms chunks, that's 50 per block.  might be a few that don't arrive in time to be included in block.";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:12 AM";"No";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:12 AM";"the tx are in blocks";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:12 AM";"each tx is taking the change of the previous tx";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:12 AM";"once the block is added to the chain";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:12 AM";"every tx/packet of data is in order";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:13 AM";"it cannot be out of order";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:13 AM";"once the block is confiirmed ... if the connections sucks... you need to wait for a longer buffer";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:15 AM";"all the blocks come from the same node";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:15 AM";"there is no possible way it can get out of order";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:15 AM";"guess until I make it work ... people wont understand this üòõ";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 01:16 AM";"Got lucky and both kids are out today, so should have something basic working in 3-4H unless I made a major fuck up I dont see.";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 08:14 AM";"got distracted making new RPC call lol ...";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 08:14 AM";"its all experiance thats getting me faster and faster at this though... will return to streamer RPCs once I finish up on these ones.";"";"üëç (1)";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:30 PM";"`getdatafromblock` RPC in komodod is working for the most part.";"";"";
"455741312273219595";"jl777c#5810";"24-Oct-18 05:31 PM";"pushed fix for gettransaction crash";"";"üëç (1)";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:32 PM";"Given a block hash (fro blocknotify) or a block number it will return a JSON containing:
```""streamid""
""firsttxid""
""firstseqid""
""""lastseqid""
""data""```";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:32 PM";"no need to iterate through TXs";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:32 PM";"returns all data in a single hexstring from each block in 1 RPC call ... very very fast";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:33 PM";"stream ID is a string up to 32 chars long that identifies he stream and uses the txid spot in the first TX.";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:33 PM";"first txid is at the start of every chunk sent, allowing to seek directly to the start of the stream from any found TX, and retreive the stream ID.";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:34 PM";"You can iterat `getdatafromblock <block> false` to see which range of seqids are in that block";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:35 PM";"and start fetching data from where ever you want, or fromt he start";"";"";
"232679450301431808";"blackjok3r#3181";"24-Oct-18 05:36 PM";"Needs a few things done so it can handle more than one stream per chain (for smaller files etc)";"";"üëç (4)";
"232679450301431808";"blackjok3r#3181";"25-Oct-18 12:13 AM";"I really need to stop staying up so late working on that üòÇ";"";"";
"232679450301431808";"blackjok3r#3181";"25-Oct-18 07:42 AM";"Getting this RPC to work well, rather than just work has been a mission. But I think I made it. Still only handles 1 stream though... Not decided how exactly to handle more... Thinking a list of streamid names referanced by the first txid hash...";"";"";
"232679450301431808";"blackjok3r#3181";"25-Oct-18 07:43 AM";"or simply just a list of first txids ... seems I have a function that returns the streamid when given the firsttxid....";"";"";
"232679450301431808";"blackjok3r#3181";"25-Oct-18 07:44 AM";"so far the only thing I can thin of that will break it, is if there is 2 streams being pushed at once, however even that can be solved quite easily once I have a list of the firsttxids .";"";"";
