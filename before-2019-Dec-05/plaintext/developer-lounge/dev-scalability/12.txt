==============================================================
Guild: Komodo
Channel: dev-scalability
Topic: Discussion about Komodo scalability. Komodo has demonstrated 20,000 TPS.
Messages: 100
Range: before 05-Dec-19 12:00 AM
==============================================================

[02-Jun-18 01:47 AM] nasgifs#0000
Kmdbot tip maegus 1

[02-Jun-18 01:48 AM] nasgifs#0000
Kmdbot balance

[02-Jun-18 01:50 AM] nasgifs#0000
Kmdbot tip maegus 1.0

[02-Jun-18 01:51 AM] maegus#0000
Do .9999

[02-Jun-18 03:25 AM] imylomylo#0000
smk762 what a find.  i'll try it out

[02-Jun-18 03:25 AM] smk762#0000
üëç

[02-Jun-18 03:26 AM] imylomylo#0000
if you want to load test AWS....leave a block notify script in your config when leave komodod off for a day üò¨

[02-Jun-18 03:27 AM] smk762#0000
done a bit of digging after serverless errored. Lambda functions might also allow some aggregation, and maybe a subsequent socket emission of thin data.

[02-Jun-18 03:28 AM] imylomylo#0000
"socket emission"?  as in call out to another webservice?

[02-Jun-18 03:29 AM] smk762#0000
seems dynamodb doesn't like too much query, so looking to avoid it by feeding incoming stream events into agreagtion script, which can periodically send aggregate data

[02-Jun-18 03:30 AM] smk762#0000
socket-io via nodejs. it's what I was using for the explorer based data gathering.

[02-Jun-18 03:31 AM] smk762#0000
might not be necessary though, just I already got spare code for it.

[02-Jun-18 03:36 AM] smk762#0000
I got a good story of forgetting about aws. During last round of scaletesting, I setup kinesis, and wandered through aws reading up on things. Somehow, I setup a whole bunch of sharding while looking into capacity and cost. Can't remember hitting "buy" or "apply" though. The instance they offered with the Alooma trial was using amazon linux as the OS, which didn't play nice when I tried to build komodo, so I logged out and went back to doing work on the collector hosted with vultr.

[02-Jun-18 03:37 AM] smk762#0000
About a week later, went back to aws to see if I could link up.

[02-Jun-18 03:37 AM] smk762#0000
saw this

[02-Jun-18 03:38 AM] smk762#0000
image.png

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/452314945556578314/image.png

[02-Jun-18 03:39 AM] smk762#0000
fortunately support gave me a mulligan cos none of the tasked resources had been used.

[02-Jun-18 03:40 AM] smk762#0000
been very careful in aws ever since

[02-Jun-18 03:41 AM] imylomylo#0000
wow - yeah aws has stung me for a weekend of 2xlarge instance running once, $50.  definitely need to üëÄ

[02-Jun-18 03:42 AM] imylomylo#0000
buy a lottery ticket, or play https://stellarball.com/en.php üòÑ

[02-Jun-18 03:44 AM] smk762#0000
I cant play lotto, call it the hope tax. only value it has is the hours you sit with a ticket imagining the win, and the devestating realisation after the draw that I"m due back at work tommorow.

[02-Jun-18 03:44 AM] smk762#0000
That, and I suspect that level of unearner wealth would see me dead within a week

[02-Jun-18 03:47 AM] smk762#0000
https://twitter.com/MyWickedUnicorn/status/1002577879660670976

{Embed}
MyWickedUnicorn (@MyWickedUnicorn)
https://twitter.com/MyWickedUnicorn/status/1002577879660670976
@alistairmilne Plebeian: "Can I run up $25k of credit card debt on Amazon and pay $400 a month in interest?"

Bank: "Yes, it's your money. We here here to facilitate transactions."

Plebeian: "Can i buy $500 worth of Bitcoin?"

Bank: "No, we are here to protect you."
Retweets
129
Likes
335
Twitter

[02-Jun-18 04:04 AM] smk762#0000
Work in progress, but here's how I pictured the flow

[02-Jun-18 04:04 AM] smk762#0000
image.png

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/452321593289605133/image.png

[02-Jun-18 06:18 AM] daxirre#0000
Hey guys how are those Amazon servers for getting good cpu power?

[02-Jun-18 09:14 AM] ballwood#0000
smk762 have you guys looked at pushing the data to elasticseach? kv store so it‚Äôs like dynamo with better timestamp index support. you can then aggregate over whatever else json you submit. kibana on frontend will give you your visualizations

[02-Jun-18 09:16 AM] smk762#0000
looks interesting, cheers :thumbsup_all:

[02-Jun-18 09:27 AM] smk762#0000
updated vis start chart

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/452402951768768512/updated_vis_start_chart.png

[02-Jun-18 09:31 AM] daxirre#0000
Nice explanation

[02-Jun-18 09:32 AM] daxirre#0000
Haha üòÜ

[02-Jun-18 12:23 PM] blackjok3r#0000
whats the system load with 64 chains?

[02-Jun-18 12:23 PM] blackjok3r#0000
and can you run this command `netstat -an | grep TIME_WAIT | wc -l`

[02-Jun-18 12:25 PM] shossain#0000
Screenshot from 2018-06-02 13-24-45.png

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/452447581151428608/Screenshot_from_2018-06-02_13-24-45.png

[02-Jun-18 12:25 PM] shossain#0000
iguana using only about 9GB of RAM

[02-Jun-18 12:25 PM] shossain#0000
```
$ netstat -an | grep TIME_WAIT | wc -l
2287
```
blackjok3r ^^

[02-Jun-18 12:25 PM] blackjok3r#0000
sweet thats nothing

[02-Jun-18 12:25 PM] blackjok3r#0000
üòÑ

[02-Jun-18 12:25 PM] blackjok3r#0000
can easlly go more chains. üôÇ

[02-Jun-18 12:26 PM] shossain#0000
yes

[02-Jun-18 12:26 PM] shossain#0000
i even tested notarization only with 2 CPU threads for these 64 chains couple of days ago. it went smooth

[02-Jun-18 12:30 PM] blackjok3r#0000
There is almost no situation where all chains will have full blocks, like we are doing with these chains. So a single server may be able to notarize 256 chains even. The only thing is starting that many chains at once, requires the system to be firewalled otherwise you get port conflicts. This would be a PITA in a real world situation. Managing notary node having to do that would be annoying.

[02-Jun-18 12:51 PM] shossain#0000
though, i didn't have any blocks synced

[02-Jun-18 12:51 PM] shossain#0000
with these ccid and MoMoM printouts, we almost don't see normal notarization printouts. and, they run very fast üòõ

[02-Jun-18 12:51 PM] blackjok3r#0000
It becomes a problem only when chains you first start have TCP connections, and use up ports

[02-Jun-18 12:51 PM] blackjok3r#0000
yeah 64 chains must be intense on the prints lol

[02-Jun-18 12:51 PM] shossain#0000
yes, no notarizations yet on those chains

[02-Jun-18 12:51 PM] blackjok3r#0000
few 0's in there? is that just because not enough notarizations on those chains I guess?

[02-Jun-18 12:52 PM] shossain#0000
i mean, since i started about 30 minutes ago. it can take some time for all chains to start notarizing after iguana started

[02-Jun-18 12:52 PM] shossain#0000
12 chains remaining

[02-Jun-18 12:52 PM] blackjok3r#0000
For sure. We have already found and fixed a lot of bottlenecks.

[02-Jun-18 12:52 PM] shossain#0000
this scaletest will help mainnet notary nodes as well

[02-Jun-18 12:52 PM] shossain#0000
yep

[02-Jun-18 12:58 PM] shossain#0000
9 chains remaining now

[02-Jun-18 01:15 PM] nasgifs#0000
Kmdbot tip maegus 0.9999

[02-Jun-18 03:50 PM] shossain#0000
1 chain left, 63 notarizing consistently

[02-Jun-18 04:10 PM] libscott#0000
Not seeing notarisations for TXSCL

[02-Jun-18 04:10 PM] libscott#0000
sorry, dont mean to sound ungrateful.. üòÜ

[02-Jun-18 04:11 PM] shossain#0000
yes, just funded KMD on one node. noticed that it ran out of KMD 20 minutes ago

[02-Jun-18 04:11 PM] libscott#0000
ooo. so we should be seeing one soon

[02-Jun-18 04:11 PM] shossain#0000
TXSCL didn't have notarization for last 15 hours.

[02-Jun-18 04:11 PM] shossain#0000
other chains has notarization

[02-Jun-18 04:12 PM] libscott#0000
yea, there were 2200 notarisations since the last one for TXSCL üôÇ

[02-Jun-18 04:12 PM] shossain#0000
latest ones were happened 19 minutes ago

[02-Jun-18 04:13 PM] shossain#0000
notarization started again

[02-Jun-18 05:59 PM] shossain#0000
TXSCL has notarization

[02-Jun-18 06:52 PM] libscott#0000
i see it!

[02-Jun-18 10:15 PM] libscott#0000
anyone got some TXSCL? I deleted mine by accident üòï

[02-Jun-18 10:15 PM] libscott#0000
RGyP6KXDkw7cmF7RjoUmBeoRUh5mCRr4jk

[02-Jun-18 10:17 PM] shossain#0000
sending

[02-Jun-18 10:18 PM] shossain#0000
e190146defdc0221de29f896eeb9603d3fb47d03b97ceb9a438804f1bbbbc673

[02-Jun-18 10:18 PM] shossain#0000
sent

[02-Jun-18 10:18 PM] libscott#0000
thanks! üôÇ

[02-Jun-18 10:50 PM] shossain#0000
The MoMoM list is getting bigger

[02-Jun-18 11:00 PM] libscott#0000
üòÆ what's that

[02-Jun-18 11:04 PM] shossain#0000
those big list is being printed now

[02-Jun-18 11:07 PM] shossain#0000
all MoMoMs?

[03-Jun-18 12:43 AM] libscott#0000
no, they're moms

[03-Jun-18 12:43 AM] libscott#0000
the leaf nodes of the MoMoM

[03-Jun-18 07:55 AM] blackjok3r#0000
I have modified my docker images so that both tests are run in one go. it first blasts 1 payment TX's then blasts 100 payments. I just need to calibrate how long to wait between these so that nothing overlaps.

[03-Jun-18 07:56 AM] blackjok3r#0000
I am running out of improvements to make, and will soon need AWS access so we can figure out the shared storage and how much vCPU is required for each chain.

[03-Jun-18 07:58 AM] jl777#0000
time for the AWS talk so we can get the ball rolling on the world record test

[03-Jun-18 08:06 AM] blackjok3r#0000
I need to make sure its 100% working for a few tests but its safe to say I think its good. By the end of tomorrow it will defiantly be finished. There is only the stats end left now. Currently all the data is pushed to that AWS dynamoDB its just up to @Mylo and smk762 to work out what to do with it.

[03-Jun-18 08:08 AM] jl777#0000
have we verified the data is good

[03-Jun-18 08:18 AM] blackjok3r#0000
It should be fine. All i am doing is taking the length of the .tx in `getblock` rather than pushing all the transaction hashes. the code is all commented if anyone wants to check it. 
its located here: https://github.com/blackjok3rtt/scaletest_containers/tree/1payment2

{Embed}
https://github.com/blackjok3rtt/scaletest_containers/tree/1payment2
blackjok3rtt/scaletest_containers
Contribute to scaletest_containers development by creating an account on GitHub.
https://avatars3.githubusercontent.com/u/30971146?s=400&v=4

[03-Jun-18 07:29 PM] shossain#0000
1500 notarizations in 5 hours. every hour doing about 300 and 5 each minute

[04-Jun-18 12:20 AM] manfromaus#0000
Someone mentioned wanting numbers around BTC average payments/tx - this article should give some useful info: https://coinmetrics.io/batching/

[04-Jun-18 12:21 AM] manfromaus#0000
for the "real world" comparative test

[04-Jun-18 12:59 AM] smk762#0000
updated star chart

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/452999798539157526/updated_star_chart.png

[04-Jun-18 01:00 AM] smk762#0000
updated star chart

{Attachments}
https://cdn.discordapp.com/attachments/449949868904022036/453000077380681739/updated_star_chart.png

[04-Jun-18 01:01 AM] emmanux#0000
lol

[04-Jun-18 04:21 AM] jl777#0000
batching: "Batching accounts for roughly 12% of all transactions, 40% of all outputs, and 30‚Äì60% of all raw BTC output value. Not bad."

[04-Jun-18 04:22 AM] jl777#0000
maybe we need to do more education about the benefits of batching. For most businesses that are not time sensitive in payments, they can batch 100 tx into a single one and save 90% of space

[04-Jun-18 04:29 AM] smk762#0000
payroll is common and an obvious use case.

[04-Jun-18 04:31 AM] jl777#0000
yes for that it can even become a 1000 payment tx

[04-Jun-18 04:32 AM] jl777#0000
but also payables, i can see an automate payments batching system that companies use that combines multisig approvals to save costs for BTC txfees, and once this is available it would work with any bitcoin protocol coin

[04-Jun-18 04:37 AM] blackjok3r#0000
Yes. We strongly encourage any analysts, investors, journalists, and developers to look past mere transaction count from now on. *The default measure of Bitcoin‚Äôs performance should be ‚Äúpayments per day‚Äù rather than transaction count.* This also makes Bitcoin more comparable with other UTXO chains. They generally have significantly variable payments-per-transaction ratios, so just using payments standardizes that. (Stay tuned: Coinmetrics will be rolling out tools to facilitate this very soon.)

[04-Jun-18 04:37 AM] blackjok3r#0000
ü§î

[04-Jun-18 05:25 AM] imylomylo#0000
ok.  thanks for req

[04-Jun-18 05:34 AM] smk762#0000
percentage levies on payment processing (visa, mastercard), plus potential interest on the debt incurred, and inflation caused, all while giving up trade privacy and being subject to profiling based on purchase item/time/locatation
vs.
low flat rate fee for batch payment processing + opt-in methodology for sharing private metadata

